{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35638194",
   "metadata": {},
   "source": [
    "# 1. What is a parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5946d",
   "metadata": {},
   "source": [
    "In Machine Learning, a **parameter** is a value that the model **learns from the data** to make predictions.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "**1. Linear Regression:**  \n",
    "\\[\n",
    "y = w \\cdot x + b\n",
    "\\]  \n",
    "- `w` (weight) and `b` (bias) are **parameters**.  \n",
    "- The model **learns the best values** of `w` and `b` during training.\n",
    "\n",
    "**2. Neural Networks:**  \n",
    "- Parameters are the **weights and biases** of all neurons.  \n",
    "- These are updated during training using **gradient descent**.\n",
    "\n",
    "**Key Point:**  \n",
    "> Parameters are **internal variables of the model** that are adjusted during training to fit the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71d56f",
   "metadata": {},
   "source": [
    "# 2.  What is correlation?  What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2741a",
   "metadata": {},
   "source": [
    "**Correlation** measures the **relationship between two variables**.  \n",
    "It tells us how one variable **changes when the other changes**.\n",
    "\n",
    "### Key Points:\n",
    "- Correlation ranges from **-1 to 1**.\n",
    "  - `1` → Perfect positive correlation (both increase together)  \n",
    "  - `-1` → Perfect negative correlation (one increases, other decreases)  \n",
    "  - `0` → No correlation (no linear relationship)\n",
    "\n",
    "### Example:\n",
    "- Height and Weight usually have a **positive correlation**.  \n",
    "- Ice cream sales and temperature also show **positive correlation**.  \n",
    "- Number of hours studied and number of errors made might have a **negative correlation**.\n",
    "\n",
    "\n",
    "**Key Point:**  \n",
    "> Correlation shows **strength and direction** of a linear relationship, but **does not imply causation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e5d0e",
   "metadata": {},
   "source": [
    "# 3.  Define Machine Learning. What are the main components in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db788d",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "**Definition:**  \n",
    "Machine Learning (ML) is a branch of Artificial Intelligence (AI) that allows computers to **learn from data** and **make predictions or decisions** without being explicitly programmed.\n",
    "\n",
    "\n",
    "## Main Components of Machine Learning\n",
    "\n",
    "1. **Data**  \n",
    "   - The foundation of ML. Can be **structured** (tables) or **unstructured** (images, text, audio).  \n",
    "\n",
    "2. **Features**  \n",
    "   - Input variables used to train the model.  \n",
    "   - Example: In predicting house prices, features can be size, location, number of rooms.  \n",
    "\n",
    "3. **Model**  \n",
    "   - A mathematical representation that **learns patterns** from data.  \n",
    "   - Example: Linear Regression, Decision Trees, Neural Networks.  \n",
    "\n",
    "4. **Parameters**  \n",
    "   - Internal variables that the model **learns from data**.  \n",
    "   - Example: Weights and biases in a neural network.  \n",
    "\n",
    "5. **Algorithm**  \n",
    "   - The method used to **train the model** and **update parameters**.  \n",
    "   - Example: Gradient Descent, Random Forest Algorithm.  \n",
    "\n",
    "6. **Evaluation**  \n",
    "   - Measuring how well the model **performs on new data**.  \n",
    "   - Example: Accuracy, RMSE, F1-Score.  \n",
    "\n",
    "> **Key Point:**  \n",
    "> Machine Learning is all about **feeding data to a model**, letting it **learn patterns**, and then **making predictions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa5f8e",
   "metadata": {},
   "source": [
    "# 4.  How does loss value help in determining whether the model is good or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd10b18",
   "metadata": {},
   "source": [
    "**Definition of Loss:**  \n",
    "Loss is a **measure of how well a model's predictions match the actual results**.  \n",
    "- Lower loss → predictions are closer to true values.  \n",
    "- Higher loss → predictions are far from true values.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Model Training:**  \n",
    "   - During training, the model **tries to minimize the loss**.  \n",
    "   - Algorithms like **Gradient Descent** adjust parameters to reduce loss.\n",
    "\n",
    "2. **Determining Model Quality:**  \n",
    "   - A **low loss** usually indicates a **good model**.  \n",
    "   - A **high loss** indicates the model is **not fitting the data well**.\n",
    "\n",
    "3. **Types of Loss Functions:**  \n",
    "   - **Regression:** Mean Squared Error (MSE), Mean Absolute Error (MAE)  \n",
    "   - **Classification:** Cross-Entropy Loss  \n",
    "\n",
    "> **Key Point:**  \n",
    "> Loss value gives a **quantitative way to judge model performance**. Lower loss generally means a better model, but it should also be checked on **test/validation data** to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc580d2",
   "metadata": {},
   "source": [
    "# 5.  What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53692c49",
   "metadata": {},
   "source": [
    "## Continuous and Categorical Variables\n",
    "\n",
    "In Machine Learning, variables (features) can be of different types. Two common types are **continuous** and **categorical**.\n",
    "\n",
    "### 1. Continuous Variables\n",
    "- Can take **any numeric value** within a range.  \n",
    "- Usually measured, not counted.  \n",
    "- Examples:  \n",
    "  - Height (150.5 cm, 160.2 cm, etc.)  \n",
    "  - Weight (55.3 kg, 70.1 kg)  \n",
    "  - Temperature (36.6°C, 37.2°C)  \n",
    "\n",
    "**Key Point:** Continuous variables are **numeric and can have decimals**.\n",
    "\n",
    "\n",
    "### 2. Categorical Variables\n",
    "- Represent **distinct categories or groups**.  \n",
    "- Usually counted, not measured.  \n",
    "- Examples:  \n",
    "  - Gender (Male, Female)  \n",
    "  - Color (Red, Blue, Green)  \n",
    "  - Payment Method (Cash, Card, UPI)  \n",
    "\n",
    "**Key Point:** Categorical variables are **non-numeric or discrete labels**, sometimes encoded as numbers for ML.\n",
    "\n",
    "> **Summary:**  \n",
    "> - Continuous → numeric, measurable  \n",
    "> - Categorical → groups or labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964626e",
   "metadata": {},
   "source": [
    "# 6.  How do we handle categorical variables in Machine Learning? What are the common techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9fdb29",
   "metadata": {},
   "source": [
    "## Handling Categorical Variables in Machine Learning\n",
    "\n",
    "Categorical variables cannot be directly used by most machine learning models because they **require numeric input**.  \n",
    "So, we **convert categorical variables into numeric forms** using different techniques.\n",
    "\n",
    "### Common Techniques:\n",
    "\n",
    "1. **Label Encoding**  \n",
    "   - Assigns a unique number to each category.  \n",
    "   - Example:  \n",
    "     - `Red → 0, Blue → 1, Green → 2`  \n",
    "   - Useful for **ordinal variables** (with order).  \n",
    "\n",
    "2. **One-Hot Encoding**  \n",
    "   - Creates **binary columns** for each category.  \n",
    "   - Example: Color = {Red, Blue, Green}  \n",
    "\n",
    "   | Red | Blue | Green |  \n",
    "   |-----|------|-------|  \n",
    "   | 1   | 0    | 0     |  \n",
    "   | 0   | 1    | 0     |  \n",
    "   | 0   | 0    | 1     |  \n",
    "\n",
    "   - Useful for **nominal variables** (no order).\n",
    "\n",
    "3. **Binary Encoding / Other Encodings**  \n",
    "   - Combines techniques for **high-cardinality features** (many unique categories).  \n",
    "   - Reduces **dimensionality** compared to one-hot encoding.\n",
    "\n",
    "> **Key Point:**  \n",
    "> Converting categorical variables to numeric allows the model to **understand patterns** in the data. The choice of technique depends on the **type and number of categories**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16499252",
   "metadata": {},
   "source": [
    "# 7. What do you mean by training and testing a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6006c2",
   "metadata": {},
   "source": [
    "## Training and Testing a Dataset\n",
    "\n",
    "In Machine Learning, we **split our data** to make sure the model can **learn patterns** and also **perform well on new data**.\n",
    "\n",
    "\n",
    "### 1. Training Dataset\n",
    "- Used to **train the model**.  \n",
    "- The model **learns patterns and relationships** from this data.  \n",
    "- Example: For predicting house prices, the model sees many examples of houses with features and prices.  \n",
    "\n",
    "### 2. Testing Dataset\n",
    "- Used to **evaluate the model** after training.  \n",
    "- Contains **new data that the model has not seen**.  \n",
    "- Helps to check if the model **generalizes well** to unseen data.  \n",
    "\n",
    "\n",
    "### Key Point:\n",
    "> **Training dataset → learning**  \n",
    "> **Testing dataset → evaluation / performance check**  \n",
    "\n",
    "**Example Analogy:**  \n",
    "- Training = studying for an exam using books and notes.  \n",
    "- Testing = taking the exam to see how much you actually learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc44008",
   "metadata": {},
   "source": [
    "# 8.  What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588b6ae",
   "metadata": {},
   "source": [
    "## sklearn.preprocessing\n",
    "\n",
    "**`sklearn.preprocessing`** is a module in **Scikit-Learn** that provides tools to **prepare and transform data** before feeding it to a machine learning model.  \n",
    "\n",
    "### Why Preprocessing is Needed:\n",
    "- Many ML models work better when **features are scaled or normalized**.  \n",
    "- Categorical data needs to be **converted to numeric**.  \n",
    "- It helps models **learn faster and perform better**.\n",
    "\n",
    "### Common Tasks in `sklearn.preprocessing`:\n",
    "\n",
    "1. **Scaling / Normalization**  \n",
    "   - `StandardScaler` → Scales data to have **mean = 0** and **std = 1**  \n",
    "   - `MinMaxScaler` → Scales data to a **range [0, 1]**  \n",
    "\n",
    "2. **Encoding Categorical Variables**  \n",
    "   - `OneHotEncoder` → Converts categorical data to **binary columns**  \n",
    "   - `LabelEncoder` → Converts categories to **numbers**\n",
    "\n",
    "3. **Other Transformations**  \n",
    "   - `PolynomialFeatures` → Generate **polynomial and interaction features**  \n",
    "   - `Binarizer` → Convert numerical values into **0 or 1** based on a threshold  \n",
    "\n",
    "> **Key Point:**  \n",
    "> `sklearn.preprocessing` is used to **clean, scale, and transform data** so that machine learning models can **understand and learn effectively**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14fdd5",
   "metadata": {},
   "source": [
    "# 9. What is a Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b91e9b",
   "metadata": {},
   "source": [
    "## Test Set\n",
    "\n",
    "In Machine Learning, a **test set** is a portion of the dataset that is **kept aside** and **not used during training**.  \n",
    "\n",
    "### Purpose:\n",
    "- To **evaluate the performance** of the trained model.  \n",
    "- To check if the model **generalizes well** to new, unseen data.  \n",
    "\n",
    "### Key Points:\n",
    "- Usually, data is split into **training set** and **test set** (common split: 70% train, 30% test).  \n",
    "- Helps to detect **overfitting** (model performs well on training data but poorly on new data).  \n",
    "- Model metrics like **accuracy, RMSE, or F1-score** are calculated on the test set.\n",
    "\n",
    "**Example Analogy:**  \n",
    "- Training set = studying for an exam.  \n",
    "- Test set = taking the exam to see how much you learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b9938",
   "metadata": {},
   "source": [
    "# 10.  How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d76a39",
   "metadata": {},
   "source": [
    "## 1. Splitting Data for Model Fitting in Python\n",
    "\n",
    "In Machine Learning, we usually **split the dataset** into a **training set** and a **test set**.  \n",
    "This helps the model **learn from training data** and **evaluate on unseen test data**.\n",
    "\n",
    "### Using Scikit-Learn:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = features, y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b33169",
   "metadata": {},
   "source": [
    "``` python \n",
    "Problem Understanding\n",
    "│\n",
    "▼\n",
    "\n",
    "Data Collection\n",
    "│\n",
    "▼\n",
    "\n",
    "Data Preprocessing\n",
    "(handling missing values, encoding categorical variables, scaling)\n",
    "│\n",
    "▼\n",
    "\n",
    "Train-Test Split\n",
    "│\n",
    "▼\n",
    "\n",
    "Model Selection\n",
    "│\n",
    "▼\n",
    "\n",
    "Model Training\n",
    "│\n",
    "▼\n",
    "\n",
    "Model Evaluation\n",
    "(accuracy, RMSE, F1-score, etc.)\n",
    "│\n",
    "▼\n",
    "\n",
    "Hyperparameter Tuning\n",
    "│\n",
    "▼\n",
    "\n",
    "Deployment / Prediction```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb056d",
   "metadata": {},
   "source": [
    "\n",
    "> **Key Point:** Follow these steps **systematically** to solve any ML problem effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6fc01",
   "metadata": {},
   "source": [
    "# 11. Why do we have to perform EDA before fitting a model to the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22261f93",
   "metadata": {},
   "source": [
    "**EDA (Exploratory Data Analysis)** is the process of **understanding and analyzing the data** before building a machine learning model.  \n",
    "\n",
    "### Reasons to Perform EDA:\n",
    "\n",
    "1. **Understand the Data**  \n",
    "   - Know the **types of variables**, distributions, and relationships between features.  \n",
    "   - Example: Check if a variable is numeric or categorical.\n",
    "\n",
    "2. **Detect Missing Values and Outliers**  \n",
    "   - Missing or extreme values can **bias the model** or cause errors.  \n",
    "   - EDA helps decide how to **handle them** (impute, remove, or transform).\n",
    "\n",
    "3. **Feature Selection and Engineering**  \n",
    "   - Identify **important features** that affect the target variable.  \n",
    "   - Create new features if needed for better model performance.\n",
    "\n",
    "4. **Understand Relationships and Correlations**  \n",
    "   - Check how features are **related to each other and the target**.  \n",
    "   - Helps in avoiding **multicollinearity** in some models.\n",
    "\n",
    "5. **Guide Model Choice**  \n",
    "   - Data insights can **suggest the right algorithm**.  \n",
    "   - Example: Non-linear patterns may require tree-based models.\n",
    "\n",
    "> **Key Point:**  \n",
    "> EDA ensures we **clean, understand, and prepare the data** properly, which leads to **better model performance and fewer surprises** during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2114f8",
   "metadata": {},
   "source": [
    "# 12. What is Correlation?\n",
    "\n",
    "**Correlation** measures the **relationship between two variables**.  \n",
    "It tells us how one variable **changes when the other changes**.\n",
    "\n",
    "### Key Points:\n",
    "- Correlation ranges from **-1 to 1**.\n",
    "  - `1` → Perfect positive correlation (both increase together)  \n",
    "  - `-1` → Perfect negative correlation (one increases, other decreases)  \n",
    "  - `0` → No correlation (no linear relationship)\n",
    "\n",
    "### Example:\n",
    "- Height and Weight usually have a **positive correlation**.  \n",
    "- Ice cream sales and temperature also show **positive correlation**.  \n",
    "- Number of hours studied and number of errors made might have a **negative correlation**.\n",
    "\n",
    "\n",
    "**Key Point:**  \n",
    "> Correlation shows **strength and direction** of a linear relationship, but **does not imply causation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092ddd9",
   "metadata": {},
   "source": [
    "# 13. What is negative correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc979256",
   "metadata": {},
   "source": [
    "## Negative Correlation\n",
    "\n",
    "**Definition:**  \n",
    "Negative correlation occurs when **one variable increases while the other decreases**, and vice versa.  \n",
    "\n",
    "### Key Points:\n",
    "- Correlation value is **between -1 and 0**.  \n",
    "  - `-1` → Perfect negative correlation (strongest inverse relationship)  \n",
    "  - `0` → No correlation  \n",
    "\n",
    "### Examples:\n",
    "- Number of hours studied vs. number of errors made  \n",
    "- Speed of a car vs. travel time for a fixed distance  \n",
    "- Temperature vs. heating bill (usually)\n",
    "\n",
    "> **Key Point:**  \n",
    "> Negative correlation indicates an **inverse relationship** between two variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e38a28",
   "metadata": {},
   "source": [
    "# 14. How can you find correlation between variables in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba4737",
   "metadata": {},
   "source": [
    "## Finding Correlation Between Variables in Python\n",
    "\n",
    "Correlation measures the **relationship between two variables**.  \n",
    "In Python, we can easily calculate it using **pandas**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd41a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Height   Weight\n",
      "Height  1.00000  0.99485\n",
      "Weight  0.99485  1.00000\n"
     ]
    }
   ],
   "source": [
    "# Using `corr()` Method\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {'Height': [150, 160, 170, 180, 190],\n",
    "        'Weight': [50, 60, 65, 75, 85]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5802bd",
   "metadata": {},
   "source": [
    "# 15.  What is causation? Explain difference between correlation and causation with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b459072",
   "metadata": {},
   "source": [
    "\n",
    "**Causation** means that **one event directly causes another**.  \n",
    "- Example: Pressing a light switch **causes** the light to turn on.  \n",
    "- In Machine Learning, causation is about **direct influence**, not just observed relationships.\n",
    "\n",
    "\n",
    "### Difference Between Correlation and Causation\n",
    "\n",
    "| Feature          | Correlation                          | Causation                          |\n",
    "|-----------------|--------------------------------------|-----------------------------------|\n",
    "| Meaning          | Two variables **change together**    | One variable **directly affects** the other |\n",
    "| Direction        | Can be positive or negative          | Always implies a cause-effect relationship |\n",
    "| Implies          | **Association** only                 | **Direct effect**                  |\n",
    "| Example          | Ice cream sales ↑ & temperature ↑     | Smoking → Lung cancer              |\n",
    "\n",
    "**Key Point:**  \n",
    "> Correlation **does not imply causation**. Just because two things happen together, it doesn’t mean one causes the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b017ee",
   "metadata": {},
   "source": [
    "# 16.  What is an Optimizer? What are different types of optimizers? Explain each with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a46e1b",
   "metadata": {},
   "source": [
    "\n",
    "An **optimizer** is an algorithm used to **update the parameters (weights and biases) of a model** to **minimize the loss function** during training.  \n",
    "- Goal: Make the model **learn better** and converge faster.  \n",
    "- Example: In Linear Regression, the optimizer adjusts `w` and `b` to reduce Mean Squared Error.\n",
    "\n",
    "\n",
    "### Types of Optimizers\n",
    "\n",
    "1. **Gradient Descent (GD)**\n",
    "   - Updates parameters using the **gradient of the loss function**.  \n",
    "   - Formula:  \n",
    "     \\[\n",
    "     \\theta = \\theta - \\eta \\cdot \\nabla_\\theta L\n",
    "     \\]  \n",
    "     - `θ` = parameter, `η` = learning rate, `L` = loss  \n",
    "   - Example: Batch Gradient Descent updates after **calculating gradient on the full dataset**.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**\n",
    "   - Updates parameters **for each training example** instead of full dataset.  \n",
    "   - Faster but may fluctuate a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1b942",
   "metadata": {},
   "source": [
    "# 17. What is sklearn.linear_model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aeee77",
   "metadata": {},
   "source": [
    "\n",
    "**`sklearn.linear_model`** is a module in **Scikit-Learn** that provides **linear models** for regression and classification tasks.  \n",
    "Linear models are those where the **output is a linear combination of input features**.\n",
    "\n",
    "\n",
    "### Common Classes in `sklearn.linear_model`:\n",
    "\n",
    "1. **LinearRegression**  \n",
    "   - Performs **ordinary least squares linear regression**.  \n",
    "   - Example: Predicting house prices based on size and location.  \n",
    "\n",
    "   ```python\n",
    "   from sklearn.linear_model import LinearRegression\n",
    "   model = LinearRegression()\n",
    "   model.fit(X_train, y_train)\n",
    "   y_pred = model.predict(X_test)\n",
    "2. **LogisticRegression**\n",
    "    - Used for binary or multi-class classification.\n",
    "    - Example: Predicting if a student passes (1) or fails (0) based on study hours\n",
    "    ``` python\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "3. **Ridge & Lasso Regression**\n",
    "    - Regularized linear regression to prevent overfitting.\n",
    "    - Ridge → L2 regularization, Lasso → L1 regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a863f5",
   "metadata": {},
   "source": [
    "# 18.  What does model.fit() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654bc87",
   "metadata": {},
   "source": [
    "\n",
    "The `fit()` method in **Scikit-Learn** is used to **train a machine learning model** on a given dataset.  \n",
    "- It **learns the patterns** in the training data.  \n",
    "- Updates the **model parameters** (like weights and biases) to minimize the loss.\n",
    "\n",
    "\n",
    "### Arguments of `model.fit()`\n",
    "\n",
    "1. **`X`** → Features / Input variables  \n",
    "   - Can be a **DataFrame, array, or matrix**.  \n",
    "   - Shape: `(n_samples, n_features)`  \n",
    "\n",
    "2. **`y`** → Target / Output variable  \n",
    "   - Can be a **Series, array, or list**.  \n",
    "   - Shape: `(n_samples,)` for single output, `(n_samples, n_targets)` for multiple outputs  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# X = features, y = target\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  # Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c67f1",
   "metadata": {},
   "source": [
    "# 19. What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc47952",
   "metadata": {},
   "source": [
    "\n",
    "- The `predict()` method is used to **generate predictions** from a **trained model**.  \n",
    "- It applies the patterns learned during `model.fit()` to **new/unseen input data**.  \n",
    "- The output depends on the type of model:\n",
    "  - Regression → returns continuous values (e.g., house prices).  \n",
    "  - Classification → returns class labels (e.g., 0 or 1).  \n",
    "\n",
    "\n",
    "### Arguments of `model.predict()`\n",
    "\n",
    "1. **`X`** → Features / Input data on which predictions are required.  \n",
    "   - Format: array, list, or DataFrame.  \n",
    "   - Shape: `(n_samples, n_features)`  \n",
    "\n",
    "Important: `predict()` **does not take the target variable (`y`)**, only the features (`X`).  \n",
    "\n",
    "### Example:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Training\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)  # Predict values for new input data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d56816b",
   "metadata": {},
   "source": [
    "# 20.  What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea00da",
   "metadata": {},
   "source": [
    "## Continuous and Categorical Variables\n",
    "\n",
    "### 1. Continuous Variables\n",
    "- Variables that can take **any numerical value within a range**.  \n",
    "- They are **measurable** and often come from real-world measurements.  \n",
    "- Examples:  \n",
    "  - Height (170.5 cm, 172.3 cm)  \n",
    "  - Weight (65.2 kg, 70.8 kg)  \n",
    "  - Temperature (36.7°C, 40.1°C)  \n",
    "\n",
    "-\n",
    "### 2. Categorical Variables\n",
    "- Variables that represent **categories or groups** instead of numbers.  \n",
    "- They are **qualitative** in nature.  \n",
    "- Can be divided into:\n",
    "  - **Nominal:** No natural order (e.g., colors: Red, Blue, Green).  \n",
    "  - **Ordinal:** Have an order (e.g., education level: High School < Graduate < Postgraduate).  \n",
    "\n",
    "- Examples:  \n",
    "  - Gender (Male, Female)  \n",
    "  - City (Delhi, Mumbai, Kolkata)  \n",
    "  - Grade (A, B, C)  \n",
    "\n",
    "\n",
    "> **Key Difference:**  \n",
    "> - Continuous → Numbers that can be measured on a scale.  \n",
    "> - Categorical → Labels or groups used for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59291389",
   "metadata": {},
   "source": [
    "# 21.  What is feature scaling? How does it help in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac4473",
   "metadata": {},
   "source": [
    "\n",
    "Feature scaling is the process of **transforming the values of features (input variables) into a similar scale** so that no feature dominates others due to its magnitude.  \n",
    "- Example: Age (20–60) vs. Salary (10,000–1,00,000).  \n",
    "- Without scaling, the model may give **more importance to features with larger values**.\n",
    "\n",
    "\n",
    "### Why is Feature Scaling Important?\n",
    "1. **Improves performance of algorithms**  \n",
    "   - Many ML algorithms (e.g., KNN, SVM, Logistic Regression) work better when features are on a similar scale.  \n",
    "2. **Faster convergence** in optimization-based algorithms like Gradient Descent.  \n",
    "3. Prevents one feature from **dominating** due to larger numerical values.  \n",
    "\n",
    "\n",
    "### Common Techniques of Feature Scaling\n",
    "\n",
    "1. **Min-Max Normalization (Scaling between 0 and 1)**  \n",
    "   Formula:  \n",
    "   \\[\n",
    "   X' = \\frac{X - X_{min}}{X_{max} - X_{min}}\n",
    "   \\]  \n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import MinMaxScaler\n",
    "   scaler = MinMaxScaler()\n",
    "   X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ae499",
   "metadata": {},
   "source": [
    "# 22.  How do we perform scaling in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864538f",
   "metadata": {},
   "source": [
    "We can perform scaling using **Scikit-Learn's preprocessing module**.\n",
    "1. Min-Max Scaling (Normalization: values between 0 and 1)\n",
    "2. Standardization (Z-score scaling: mean = 0, std = 1)\n",
    "3. Robust Scaling (useful when data has outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d553500",
   "metadata": {},
   "source": [
    "# 23. What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904c7ba",
   "metadata": {},
   "source": [
    "\n",
    "The **`sklearn.preprocessing`** module in Scikit-Learn provides **functions and classes** to:\n",
    "- Transform features before training a model.\n",
    "- Make data suitable for Machine Learning algorithms.\n",
    "\n",
    "It mainly helps in:\n",
    "1. **Scaling** numerical data (so all features are on the same scale).  \n",
    "2. **Encoding** categorical variables (convert text labels into numbers).  \n",
    "3. **Transforming** data into forms that ML models can use effectively.  \n",
    "\n",
    "\n",
    "### Common Functions in `sklearn.preprocessing`\n",
    "\n",
    "1. **Scaling and Normalization**\n",
    "   - `StandardScaler()` → Standardization (mean=0, std=1)  \n",
    "   - `MinMaxScaler()` → Normalization (values between 0 and 1)  \n",
    "   - `RobustScaler()` → Scaling robust to outliers  \n",
    "\n",
    "2. **Encoding Categorical Data**\n",
    "   - `LabelEncoder()` → Converts categories into numbers (e.g., Male=0, Female=1)  \n",
    "   - `OneHotEncoder()` → Creates binary columns for each category  \n",
    "\n",
    "3. **Other Utilities**\n",
    "   - `Binarizer()` → Converts values above a threshold into 1, others into 0  \n",
    "   - `PolynomialFeatures()` → Generates polynomial features for linear models  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55379809",
   "metadata": {},
   "source": [
    "# 24. How do we split data for model fitting (training and testing) in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da2bb9",
   "metadata": {},
   "source": [
    "\n",
    "- In Machine Learning, we divide the dataset into:\n",
    "  1. **Training Set** → Used to train (fit) the model.  \n",
    "  2. **Testing Set** → Used to evaluate how well the model generalizes to unseen data.  \n",
    "\n",
    "This helps to **prevent overfitting** and gives a fair estimate of model performance.\n",
    "\n",
    "### Using Scikit-Learn: `train_test_split`\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {'Age': [20, 22, 25, 30, 35, 40, 45, 50],\n",
    "        'Salary': [20000, 25000, 30000, 40000, 50000, 60000, 70000, 80000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[['Age']]       # Features\n",
    "y = df['Salary']      # Target variable\n",
    "\n",
    "# Split data (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c99de2",
   "metadata": {},
   "source": [
    "# 25.  Explain data encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e55879",
   "metadata": {},
   "source": [
    "\n",
    "- Machine Learning models **work with numbers**, not text.  \n",
    "- If a dataset has **categorical (non-numeric) variables**, we need to **convert them into numeric form**.  \n",
    "- This process is called **data encoding**.  \n",
    "\n",
    "### Types of Encoding\n",
    "\n",
    "#### 1. Label Encoding\n",
    "- Converts each category into a unique **numeric label**.  \n",
    "- Example:  \n",
    "  - Gender → Male = 0, Female = 1  \n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = ['Male', 'Female', 'Female', 'Male']\n",
    "encoder = LabelEncoder()\n",
    "encoded = encoder.fit_transform(data)\n",
    "print(encoded)  # [1 0 0 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6bfb27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
